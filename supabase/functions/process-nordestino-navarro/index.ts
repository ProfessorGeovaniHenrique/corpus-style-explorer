import { serve } from 'https://deno.land/std@0.168.0/http/server.ts';
import { createClient } from 'https://esm.sh/@supabase/supabase-js@2.81.1';

const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
};

interface ProcessRequest {
  fileContent?: string;
  offsetInicial?: number;
}

interface ParsedEntry {
  verbete: string;
  verbete_normalizado: string;
  classe_gramatical: string | null;
  origem_regionalista: string[];
  variantes: string[];
  definicoes: string[];
  volume_fonte: string;
  confianca_extracao: number;
}

serve(async (req) => {
  if (req.method === 'OPTIONS') {
    return new Response(null, { headers: corsHeaders });
  }

  const supabaseUrl = Deno.env.get('SUPABASE_URL')!;
  const supabaseKey = Deno.env.get('SUPABASE_SERVICE_ROLE_KEY')!;
  const supabase = createClient(supabaseUrl, supabaseKey);

  try {
    const { fileContent, offsetInicial = 0 }: ProcessRequest = await req.json();
    
    console.log(`üìö Iniciando importa√ß√£o do Dicion√°rio do Nordeste (Navarro 2014) - offset: ${offsetInicial}`);

    // Criar job de importa√ß√£o
    const { data: job, error: jobError } = await supabase
      .from('dictionary_import_jobs')
      .insert({
        tipo_dicionario: 'nordestino_navarro',
        status: 'iniciado',
        offset_inicial: offsetInicial,
        metadata: {
          fonte: 'Dicion√°rio do Nordeste - Fred Navarro - 2014',
          url_github: 'https://github.com/ProfessorGeovaniHenrique/estilisticadecorpus/blob/main/public/dictionaries/Dicion%C3%A1rio%20do%20Nordeste%20--%20Fred%20Navarro%20--%202014.txt'
        }
      })
      .select()
      .single();

    if (jobError) throw jobError;

    const jobId = job.id;
    console.log(`‚úÖ Job criado: ${jobId}`);

    // Usar conte√∫do do body ou buscar do GitHub
    let content: string;
    if (fileContent) {
      console.log('üìÑ Usando conte√∫do fornecido no body');
      content = fileContent;
    } else {
      console.log('üì• Buscando arquivo do GitHub...');
      const githubUrl = 'https://raw.githubusercontent.com/ProfessorGeovaniHenrique/estilisticadecorpus/main/public/dictionaries/Dicion%C3%A1rio%20do%20Nordeste%20--%20Fred%20Navarro%20--%202014.txt';
      const response = await fetch(githubUrl);
      if (!response.ok) throw new Error(`Erro ao buscar arquivo: ${response.statusText}`);
      content = await response.text();
    }
    
    const lines = content.split('\n').filter(line => line.trim());
    console.log(`üìä Total de linhas processadas: ${lines.length}`);

    // Processar em background
    processInBackground(supabase, jobId, lines, offsetInicial);

    return new Response(
      JSON.stringify({ 
        success: true, 
        jobId,
        message: 'Importa√ß√£o iniciada com sucesso'
      }),
      { headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
    );

  } catch (error: any) {
    console.error('‚ùå Erro:', error);
    return new Response(
      JSON.stringify({ error: error.message }),
      { status: 500, headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
    );
  }
});

// Fun√ß√£o para validar se √© um verbete real (n√£o metadado ou t√≠tulo)
function isValidVerbete(verbete: string): boolean {
  // Excluir verbetes muito longos (>40 chars) - provavelmente t√≠tulos
  if (verbete.length > 40) {
    console.log(`üö´ Verbete muito longo ignorado: "${verbete}"`);
    return false;
  }
  
  // Excluir t√≠tulos de obras (padr√£o "A/O + Mai√∫scula + espa√ßo + Mai√∫scula")
  if (/^(A|O|As|Os)\s+[A-Z√Å√Ä√Ç√É√â√à√ä√ç√è√ì√î√ï√ñ√ö√á√ë][a-z]+/.test(verbete)) {
    console.log(`üö´ T√≠tulo de obra ignorado: "${verbete}"`);
    return false;
  }
  
  // Excluir entradas com anos (formato NNNN-NNNN ou vol.N)
  if (/\d{4}(-\d{4})?|vol\.\s*\d+/i.test(verbete)) {
    console.log(`üö´ Entrada com ano/volume ignorada: "${verbete}"`);
    return false;
  }
  
  // Excluir palavras acad√™micas t√≠picas de metadados
  const metadataKeywords = [
    'hist√≥ria', 'mem√≥ria', 'dicion√°rio', 'literatura', 
    'imprensa', 'educa√ß√£o', 'rep√∫blica', 'revolu√ß√£o',
    'folclore', 'l√≠ngua', 'ortografia', 'norma',
    'can√ß√£o', 'bai√£o', 'cordel', 'poema'
  ];
  
  const verbeteLower = verbete.toLowerCase();
  if (metadataKeywords.some(keyword => verbeteLower.includes(keyword) && verbete.length > 15)) {
    console.log(`üö´ Metadado ignorado: "${verbete}"`);
    return false;
  }
  
  return true;
}

function parseNordestinoEntry(line: string): ParsedEntry | null {
  // Split por bullet point
  const parts = line.split('‚Ä¢').map(p => p.trim()).filter(p => p);
  
  if (parts.length < 2) return null;
  
  const verbete = parts[0].trim();
  
  // Validar se √© um verbete real
  if (!isValidVerbete(verbete)) {
    return null;
  }
  
  // Extrair TODAS as acep√ß√µes
  const acepcoes = extractAcepcoes(parts.slice(1));
  
  if (acepcoes.length === 0) return null;
  
  // Consolidar todas as acep√ß√µes em um √∫nico registro
  const allClasses = [...new Set(acepcoes.map(a => a.pos))].join(' / ');
  const allRegioes = [...new Set(acepcoes.flatMap(a => a.regioes))];
  const allVariantes = [...new Set(acepcoes.flatMap(a => a.variantes))];
  const allDefinicoes = acepcoes.flatMap(a => a.definicoes);
  
  return {
    verbete,
    verbete_normalizado: verbete.toLowerCase().normalize('NFD').replace(/[\u0300-\u036f]/g, ''),
    classe_gramatical: allClasses,
    origem_regionalista: allRegioes,
    variantes: allVariantes,
    definicoes: allDefinicoes,
    volume_fonte: 'Navarro 2014',
    confianca_extracao: 0.92
  };
}

function extractAcepcoes(parts: string[]): Array<{pos: string, regioes: string[], variantes: string[], definicoes: string[]}> {
  const acepcoes: Array<{pos: string, regioes: string[], variantes: string[], definicoes: string[]}> = [];
  let currentContent = '';
  
  for (const part of parts) {
    // Detectar in√≠cio de nova acep√ß√£o numerada (1 ‚Ä¢, 2 ‚Ä¢, etc)
    const match = part.match(/^(\d+)\s+(.+)/);
    if (match) {
      if (currentContent) {
        acepcoes.push(parseAcepcao(currentContent));
      }
      currentContent = match[2];
    } else {
      currentContent += (currentContent ? ' ‚Ä¢ ' : '') + part;
    }
  }
  
  // Adicionar √∫ltima acep√ß√£o ou √∫nica
  if (currentContent) {
    acepcoes.push(parseAcepcao(currentContent));
  }
  
  // Se n√£o h√° acep√ß√µes, tratar todo conte√∫do como √∫nica acep√ß√£o
  if (acepcoes.length === 0) {
    acepcoes.push(parseAcepcao(parts.join(' ‚Ä¢ ')));
  }
  
  return acepcoes;
}

function parseAcepcao(content: string): {pos: string, regioes: string[], variantes: string[], definicoes: string[]} {
  const posPatterns = ['s.m.', 's.f.', 's.2g.', 'v.t.d.', 'v.t.i.', 'v.int.', 'v.pron.', 'adj.', 'adv.', 'loc.', 'fraseol.'];
  let pos: string | null = null;
  const regioes: string[] = [];
  const variantes: string[] = [];
  const definicoes: string[] = [];
  
  const parts = content.split('‚Ä¢').map(p => p.trim()).filter(p => p);
  
  for (const part of parts) {
    // Detectar POS
    if (!pos && posPatterns.some(p => part.toLowerCase().includes(p))) {
      pos = part;
      continue;
    }
    
    // Detectar regi√£o (c√≥digos de estado: ba, ce, pe, etc. ou n.e.)
    if (part.match(/^[a-z]{2}$/i)) {
      regioes.push(part.toUpperCase());
      continue;
    }
    
    if (part.toLowerCase() === 'n.e.') {
      regioes.push('NORDESTE');
      continue;
    }
    
    // Detectar variantes (entre par√™nteses ou var.)
    if (part.includes('(') || part.toLowerCase().includes('var.')) {
      variantes.push(part);
      continue;
    }
    
    // Resto √© defini√ß√£o
    definicoes.push(part);
  }
  
  // Se n√£o encontrou regi√£o, assumir NORDESTE
  if (regioes.length === 0) {
    regioes.push('NORDESTE');
  }
  
  return {
    pos: pos || 's.m.',
    regioes,
    variantes,
    definicoes
  };
}

async function processInBackground(supabase: any, jobId: string, lines: string[], offsetInicial: number) {
  const BATCH_SIZE = 100;
  let processados = offsetInicial;
  let inseridos = 0;
  let erros = 0;

  try {
    await supabase
      .from('dictionary_import_jobs')
      .update({ 
        status: 'processando',
        tempo_inicio: new Date().toISOString()
      })
      .eq('id', jobId);

    const verbetes: any[] = [];

    for (let i = offsetInicial; i < lines.length; i++) {
      const line = lines[i].trim();
      
      // Filtro 1: Ignorar linhas sem bullet point
      if (!line || !line.includes('‚Ä¢')) continue;
      
      // Filtro 2: Ignorar instru√ß√µes numeradas (ex: "11. Os sin√¥nimos...")
      if (/^\d+\.\s+/.test(line)) {
        console.log(`üö´ Instru√ß√£o ignorada na linha ${i}`);
        continue;
      }
      
      // Filtro 3: Ignorar linhas com termos de instru√ß√£o espec√≠ficos
      const instructionTerms = ['sin√¥nimo', 'equivalente', 'grafado', 'aspetas', 'defini√ß√£o do verbete'];
      if (instructionTerms.some(term => line.toLowerCase().includes(term) && line.length > 50)) {
        console.log(`üö´ Metadado de instru√ß√£o ignorado na linha ${i}`);
        continue;
      }
      
      // Filtro 4: Ignorar t√≠tulos muito longos antes do primeiro bullet (>20 chars)
      const beforeBullet = line.split('‚Ä¢')[0];
      if (beforeBullet.length > 40) {
        console.log(`üö´ T√≠tulo longo ignorado na linha ${i}: "${beforeBullet.substring(0, 30)}..."`);
        continue;
      }

      try {
        const parsedEntry = parseNordestinoEntry(line);
        if (parsedEntry) {
          verbetes.push(parsedEntry);
        }
      } catch (parseError) {
        console.error(`Erro ao parsear linha ${i}:`, line, parseError);
        erros++;
      }

      // Processar em lotes
      if (verbetes.length >= BATCH_SIZE) {
        const { error: insertError } = await supabase
          .from('dialectal_lexicon')
          .upsert(verbetes, { 
            onConflict: 'verbete_normalizado',
            ignoreDuplicates: false 
          });

        if (insertError) {
          console.error('Erro ao inserir lote:', insertError);
          erros += verbetes.length;
        } else {
          inseridos += verbetes.length;
        }

        processados = i + 1;
        const progresso = (processados / lines.length) * 100;

        await supabase
          .from('dictionary_import_jobs')
          .update({
            total_verbetes: lines.length,
            verbetes_processados: processados,
            verbetes_inseridos: inseridos,
            erros,
            progresso,
            atualizado_em: new Date().toISOString()
          })
          .eq('id', jobId);

        verbetes.length = 0;
      }
    }

    // Processar √∫ltimos verbetes
    if (verbetes.length > 0) {
      const { error: insertError } = await supabase
        .from('dialectal_lexicon')
        .upsert(verbetes, { 
          onConflict: 'verbete_normalizado',
          ignoreDuplicates: false 
        });

      if (!insertError) {
        inseridos += verbetes.length;
      } else {
        erros += verbetes.length;
      }
    }

    await supabase
      .from('dictionary_import_jobs')
      .update({
        status: 'concluido',
        tempo_fim: new Date().toISOString(),
        total_verbetes: lines.length,
        verbetes_processados: lines.length,
        verbetes_inseridos: inseridos,
        erros,
        progresso: 100,
        atualizado_em: new Date().toISOString()
      })
      .eq('id', jobId);

    console.log(`‚úÖ Importa√ß√£o conclu√≠da: ${inseridos} verbetes inseridos, ${erros} erros`);

  } catch (error: any) {
    console.error('‚ùå Erro no processamento:', error);
    
    await supabase
      .from('dictionary_import_jobs')
      .update({
        status: 'erro',
        erro_mensagem: error.message,
        tempo_fim: new Date().toISOString(),
        atualizado_em: new Date().toISOString()
      })
      .eq('id', jobId);
  }
}
